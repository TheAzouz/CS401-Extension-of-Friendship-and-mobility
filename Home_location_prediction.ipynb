{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from haversine import haversine_vector, Unit\n",
    "from sklearn.cluster import DBSCAN\n",
    "from datetime import timedelta\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_latitude(lat):\n",
    "    \"\"\"\n",
    "    This function corrects for out of range latitude.\n",
    "    \n",
    "    Input: \n",
    "    -- lat: latitude coordinates in °\n",
    "    Output: \n",
    "    -- lat: latitude coordinates put between -90 and 90°\n",
    "    \"\"\"\n",
    "    while lat>90 or lat<-90:\n",
    "        if lat>90:\n",
    "            lat = -(lat-180)\n",
    "        elif lat<-90:\n",
    "            lat = -(lat+180)\n",
    "    return lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_longitude(long):\n",
    "    \"\"\"\n",
    "    This function corrects for out of range longitude.\n",
    "    \n",
    "    Input: \n",
    "    -- long: longitude coordiantes in °\n",
    "    Output: \n",
    "    -- long: longitude coordinates put between -180 and 180°\n",
    "    \"\"\"\n",
    "    while long>180 or long<-180:\n",
    "        if long>180:\n",
    "            long = long - 360\n",
    "        elif long<-180:\n",
    "            long = long +360\n",
    "    return long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(df,columns):\n",
    "    '''\n",
    "    This function computes the distance between two geographic coordinates for a given dataframe.\n",
    "    \n",
    "    Input: \n",
    "        - df: Dataframe containing 4 columns latitude1, longitude1, latitude2 and longitude2\n",
    "        - columns: list of columns [latitude1, longitude1, latitude2 and longitude2]\n",
    "        \n",
    "    Output: \n",
    "        - numpy array containing the distance between geographic coordinates of each row\n",
    "    '''\n",
    "    points1 = list(zip(df[columns[0]],df[columns[1]]))\n",
    "    points2 = list(zip(df[columns[2]],df[columns[3]]))\n",
    "    # Use harvesine_vector to compute the distance between points\n",
    "    return np.round(haversine_vector(points1,points2,Unit.KILOMETERS),decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_homes(df_homes):\n",
    "    '''\n",
    "    This function selects relevant homes. We consider a home location as relevant if it's latitude and\n",
    "    longitude doesn't \"vary much\". To measure this variation, we simply compute the mean and the std of\n",
    "    the latitude and longitude of homes for every user. Then we construct 4 points as follow:\n",
    "        - by adding and substracting the standard deviation of the latitude and longitude from their\n",
    "        respective mean\n",
    "        - Measure the diagonal in KM\n",
    "        - If the diagonal is less than 100m we can assume with confidence that the mean is indeed the\n",
    "        home location\n",
    "    Input:\n",
    "        - df_homes: A dataframe containing all checkins labled as Home\n",
    "    Output:\n",
    "        - df_homes: Home location for each user\n",
    "    '''\n",
    "    \n",
    "    # Grouping df_homes according to the user id and compute std and mean for lat and lon\n",
    "    df_homes = df_homes.groupby('User ID').agg({'lat':('std','mean'),'lon':('std','mean')})\n",
    "    \n",
    "    # Filling nan values with 0 (std return 0 if there is only one sample)\n",
    "    df_homes.fillna(0,inplace = True)\n",
    "    \n",
    "    # Construct the diagonal points\n",
    "    df_tmp = pd.DataFrame()\n",
    "    df_tmp['lat1'] = df_homes.lat['mean']-df_homes.lat['std']\n",
    "    df_tmp['lat2'] = df_homes.lat['mean']+df_homes.lat['std']\n",
    "    df_tmp['lon1'] = df_homes.lon['mean']-df_homes.lon['std']\n",
    "    df_tmp['lon2'] = df_homes.lon['mean']+df_homes.lon['std']\n",
    "    \n",
    "    # Compute diagonal length\n",
    "    df_tmp['home_radius'] = compute_distance(df_tmp,['lat1','lon1','lat2','lon2'])\n",
    "    \n",
    "    # Filter home and keep relevant home (estimated distance between homes checkins < 100m )\n",
    "    df_homes = df_homes[df_tmp['home_radius']<0.1][[('lat','mean'),('lon','mean')]].copy()\n",
    "    \n",
    "    # Flatten df_homes columns\n",
    "    df_homes.columns = df_homes.columns.get_level_values(0)\n",
    "    \n",
    "    return df_homes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_df_checkins(path,sample_frac = 1):\n",
    "    '''\n",
    "    This function takes the path of the raw data, import it and construct a checkin dataframe where\n",
    "    all users have at least 5 checkins and 1 home location\n",
    "    \n",
    "    Input:\n",
    "        - Path: the Path of the file containing the data\n",
    "        - sample_frac: sample fraction from the raw dataframe\n",
    "    Output:\n",
    "        - df_checkins: Checkin dataframe where all users have at least 5 checkins and 1 home location\n",
    "    '''\n",
    "    \n",
    "    # Read data from the file and drop unnecessary columns\n",
    "    df_tmp = pd.read_csv(path).sample(frac=sample_frac).drop(columns=['Venue ID','day'])\n",
    "    \n",
    "    # Latitude and Longitude correction\n",
    "    df_tmp.lat = df_tmp.lat.apply(correct_latitude)\n",
    "    df_tmp.lon = df_tmp.lon.apply(correct_longitude)\n",
    "    \n",
    "    # Construct df_homes and select only relevant homes\n",
    "    df_homes = df_tmp.loc[df_tmp.place.str.lower().str.contains('home' and 'private')].copy()\n",
    "    df_homes = select_relevant_homes(df_homes)\n",
    "    \n",
    "    # Select users with relevant homes from the raw data\n",
    "    df_tmp = df_tmp.loc[df_tmp['User ID'].isin(df_homes.index)].copy()\n",
    "    \n",
    "    # Count the number of checkins for each user\n",
    "    df_tmp_grouped = df_tmp.groupby('User ID').agg({'User ID':'count'})\n",
    "    \n",
    "    # Define a set containing users with at least 5 checkins\n",
    "    users = set(df_tmp_grouped[df_tmp_grouped['User ID']>5])\n",
    "    \n",
    "    # Construct df_checkins\n",
    "    df_checkins = df_tmp.loc[df_tmp['User ID'].isin(users)].copy()\n",
    "    \n",
    "    # Convert 'local time' attribute to a pandas datetime\n",
    "    df_checkins['local time'] = pd.to_datetime(df_checkins['local time'])\n",
    "    \n",
    "    # Label Homes\n",
    "    df_checkins['Is_home'] = df_checkins.place.str.lower().str.contains('home' and 'private')\n",
    "    \n",
    "    # Drop unnecessary column\n",
    "    df_checkins.drop(columns = ['place'],inplace = True)\n",
    "    \n",
    "    return df_checkins.sort_values(by=['User ID','local time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    df_checkins  = construct_df_checkins('data/processed_dataset-003.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>local time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>country</th>\n",
       "      <th>Is_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2012-04-25 14:12:50+00:00</td>\n",
       "      <td>36.292377</td>\n",
       "      <td>-119.325095</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>2012-04-25 14:56:17+00:00</td>\n",
       "      <td>36.323795</td>\n",
       "      <td>-119.348035</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2012-04-25 16:56:45+00:00</td>\n",
       "      <td>36.312187</td>\n",
       "      <td>-119.313529</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2012-04-27 08:16:23+00:00</td>\n",
       "      <td>36.292377</td>\n",
       "      <td>-119.325095</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2012-04-27 08:16:54+00:00</td>\n",
       "      <td>36.292787</td>\n",
       "      <td>-119.325866</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID                local time        lat         lon country  Is_home\n",
       "0       15 2012-04-25 14:12:50+00:00  36.292377 -119.325095      US    False\n",
       "1       15 2012-04-25 14:56:17+00:00  36.323795 -119.348035      US    False\n",
       "2       15 2012-04-25 16:56:45+00:00  36.312187 -119.313529      US    False\n",
       "3       15 2012-04-27 08:16:23+00:00  36.292377 -119.325095      US    False\n",
       "4       15 2012-04-27 08:16:54+00:00  36.292787 -119.325866      US    False"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checkins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clusters_labels(df_user,clustering_method):\n",
    "    '''\n",
    "    This function clusters the checkins for a single user.\n",
    "    Input:\n",
    "        - df_user: a dataframe containing the latitude and longitude for each checkin\n",
    "        - clustering_method: DBSCAN, we define this parameter to avoid unnecessary initialisations\n",
    "        when calling this funcrion\n",
    "    Output:\n",
    "        - clusters_labels: cluster label assigned to each checkin\n",
    "    '''\n",
    "    cluster_lables = clustering_method.fit(np.deg2rad(df_user[['lat','lon']])).labels_\n",
    "    \n",
    "    return cluster_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_user(df_user):\n",
    "    '''\n",
    "    To avoid biasing the dataset with multiple checkins in a small period of time or small distance traveled, \n",
    "    we drop checkins within \n",
    "    \n",
    "    '''\n",
    "    df_tmp = df_user.reset_index().merge(df_user.iloc[1:].reset_index(drop=True),right_index=True,\n",
    "                                         left_index=True,how='inner')\n",
    "    df_tmp['dt'] = df_tmp['local time_y'] - df_tmp['local time_x']\n",
    "    \n",
    "    columns = ['lat_x','lon_x','lat_y','lon_y']\n",
    "    df_tmp['distance'] = compute_distance(df_tmp,columns)\n",
    "    mask = (df_tmp['dt']!=timedelta(0))&((df_tmp['dt']>timedelta(hours=1))|(df_tmp['distance']>0.1))\n",
    "    \n",
    "    #print(df_tmp[['dt','distance']],mask)\n",
    "    return df_user.reset_index().iloc[df_tmp[mask].index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_checkin_during_midnight(df_user):\n",
    "    df_tmp = (df_user['local time'].dt.hour>=0) & (df_user['local time'].dt.hour<7)\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_last_checkin(df_user):\n",
    "    # We consider checkin until last\n",
    "    tmp_date = (df_user['local time']-timedelta(hours=3)).dt.date.values\n",
    "    last_checkin = []\n",
    "    # tmp_date is ordered and we can detect the last checkin whenever we detect a change \n",
    "    for i in range(len(tmp_date)-1):\n",
    "        if tmp_date[i]<tmp_date[i+1]:\n",
    "            last_checkin.append(True)\n",
    "        else:\n",
    "            last_checkin.append(False)\n",
    "    # The last checkin is always True by definition \n",
    "    last_checkin.append(True)\n",
    "    return last_checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_last_checkin_with_inactive_midnight(df_user):\n",
    "    tmp_date = (df_user['local time']-timedelta(hours=7)).dt.date.values\n",
    "    tmp_hour = (df_user['local time']).dt.hour.values\n",
    "    \n",
    "    last_checkin_with_inactive_midnight = []\n",
    "    \n",
    "    for i in range(len(tmp_date)-1):\n",
    "        if (tmp_date[i]<tmp_date[i+1]) and (tmp_hour[i]<=23):\n",
    "            last_checkin_with_inactive_midnight.append(True)\n",
    "        else:\n",
    "            last_checkin_with_inactive_midnight.append(False)\n",
    "    if tmp_hour[-1]<17:\n",
    "        last_checkin_with_inactive_midnight.append(True)\n",
    "    else:\n",
    "        last_checkin_with_inactive_midnight.append(False)\n",
    "        \n",
    "    return last_checkin_with_inactive_midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dt_to_next_checkin(df_user):\n",
    "    \n",
    "    checkin_time = df_user['local time'].values\n",
    "    delta_time = checkin_time[1:]-checkin_time[:-1]\n",
    "    delta_time = delta_time.astype(float)/(1e9*3600)\n",
    "\n",
    "    return np.append(delta_time,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ratio(column):\n",
    "    return np.sum(column)/len(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(df_checkins, sample_frac = 1):\n",
    "    \n",
    "    df_checkins  = construct_df_checkins('data/processed_dataset-003.csv',sample_frac=sample_frac)\n",
    "    \n",
    "    df_tmp = pd.DataFrame(columns = ['user','cluster_id','CR','MR','EDR','EIDR','PR','RPR','Is_home'])\n",
    "    \n",
    "    users_id, counts = np.unique(df_checkins['User ID'].values,return_counts=True)\n",
    "    grouped_checkins = df_checkins.groupby('User ID')\n",
    "    KMS_PER_RADIAN = 6371.0088\n",
    "    PRECISION = 0.1\n",
    "    clustering_method = DBSCAN(eps=PRECISION/KMS_PER_RADIAN,metric='haversine')\n",
    "    \n",
    "    for user in users_id:\n",
    "        #print('******************************',counts[i])\n",
    "        df_user = grouped_checkins.get_group(user)\n",
    "        df_user = cleaning_user(df_user).copy()\n",
    "        \n",
    "        if len(df_user)>1:\n",
    "            # Compute cluster_label\n",
    "            df_user['cluster_label'] = build_clusters_labels(df_user,clustering_method)\n",
    "            # Compute Checkin during midnight\n",
    "            df_user['checkin_during_midnight'] = compute_checkin_during_midnight(df_user)\n",
    "            # Compute last checkin\n",
    "            df_user['last_checkin'] = compute_last_checkin(df_user)\n",
    "            # Compute last checkin with inactive midnight\n",
    "            df_user['last_checkin_with_inactive_midnight'] = compute_last_checkin_with_inactive_midnight(df_user)\n",
    "            # Compute distance to next_checkin and classify edges\n",
    "            df_user['dt_to_next_checkin'] = compute_dt_to_next_checkin(df_user)\n",
    "\n",
    "            agg_dic = {'cluster_label':'count','checkin_during_midnight':compute_ratio,\n",
    "                        'last_checkin':compute_ratio,'last_checkin_with_inactive_midnight': compute_ratio,\n",
    "                        'Is_home': 'sum'}\n",
    "            rename_dic = {'cluster_label':'CR','checkin_during_midnight':'MR','last_checkin':'EDR',\n",
    "                          'last_checkin_with_inactive_midnight':'EIDR'}\n",
    "\n",
    "            grouped_clusters = df_user.groupby('cluster_label')\n",
    "\n",
    "            features = grouped_clusters.agg(agg_dic).rename(columns = rename_dic)\n",
    "            features['user'] = user\n",
    "            features['CR'] = features['CR']/features['CR'].sum()\n",
    "            features['Is_home'] = features['Is_home'] == features['Is_home'].max()\n",
    "            features['PR'],features['RPR'] = compute_PR_RPR(df_user)\n",
    "            \n",
    "            df_tmp = df_tmp.append(features)\n",
    "        \n",
    "    df_tmp['cluster_id'] = df_tmp.index \n",
    "    return df_tmp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PR_RPR(df_user):\n",
    "    df_tmp = df_user.reset_index().iloc[:-1].merge(df_user.iloc[1:].reset_index(),\n",
    "                                                    right_index=True,left_index=True)\n",
    "    df_tmp['inverse_time'] = 1/df_tmp['dt_to_next_checkin_x']\n",
    "    df_graph = df_tmp.groupby(['cluster_label_x','cluster_label_y'],as_index = False).agg({'inverse_time':'sum'})\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    RG = nx.DiGraph()\n",
    "    for i, row in df_graph.iterrows():\n",
    "        G.add_edge(int(row['cluster_label_x']),int(row['cluster_label_y']),weight=row['inverse_time'])\n",
    "        RG.add_edge(int(row['cluster_label_y']),int(row['cluster_label_x']),weight=row['inverse_time'])\n",
    "\n",
    "    return list(nx.pagerank(G, weight='weight').values()), list(nx.pagerank(RG, weight='weight').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = build_features(df_checkins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>CR</th>\n",
       "      <th>MR</th>\n",
       "      <th>EDR</th>\n",
       "      <th>EIDR</th>\n",
       "      <th>PR</th>\n",
       "      <th>RPR</th>\n",
       "      <th>Is_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.473373</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.147836</td>\n",
       "      <td>0.394836</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.036291</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.036535</td>\n",
       "      <td>0.041733</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.380939</td>\n",
       "      <td>0.246896</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.130178</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.341692</td>\n",
       "      <td>0.203941</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600331</th>\n",
       "      <td>2199190</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.765123</td>\n",
       "      <td>0.472843</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600332</th>\n",
       "      <td>2199190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.052372</td>\n",
       "      <td>0.030383</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600333</th>\n",
       "      <td>2199190</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.065619</td>\n",
       "      <td>0.323668</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600334</th>\n",
       "      <td>2199190</td>\n",
       "      <td>2</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.057655</td>\n",
       "      <td>0.096595</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600335</th>\n",
       "      <td>2199190</td>\n",
       "      <td>3</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059231</td>\n",
       "      <td>0.076512</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600336 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user  cluster_id        CR        MR       EDR      EIDR        PR  \\\n",
       "0            15          -1  0.473373  0.012500  0.150000  0.150000  0.147836   \n",
       "1            15           0  0.035503  0.000000  0.000000  0.000000  0.039053   \n",
       "2            15           1  0.053254  0.000000  0.333333  0.333333  0.036535   \n",
       "3            15           2  0.177515  0.300000  0.300000  0.333333  0.380939   \n",
       "4            15           3  0.130178  0.318182  0.272727  0.272727  0.341692   \n",
       "...         ...         ...       ...       ...       ...       ...       ...   \n",
       "600331  2199190          -1  0.762887  0.027027  0.567568  0.554054  0.765123   \n",
       "600332  2199190           0  0.061856  0.166667  0.833333  0.833333  0.052372   \n",
       "600333  2199190           1  0.061856  0.166667  0.666667  0.666667  0.065619   \n",
       "600334  2199190           2  0.051546  0.000000  0.200000  0.200000  0.057655   \n",
       "600335  2199190           3  0.061856  0.000000  1.000000  1.000000  0.059231   \n",
       "\n",
       "             RPR Is_home  \n",
       "0       0.394836   False  \n",
       "1       0.036291   False  \n",
       "2       0.041733   False  \n",
       "3       0.246896   False  \n",
       "4       0.203941    True  \n",
       "...          ...     ...  \n",
       "600331  0.472843    True  \n",
       "600332  0.030383   False  \n",
       "600333  0.323668   False  \n",
       "600334  0.096595   False  \n",
       "600335  0.076512   False  \n",
       "\n",
       "[600336 rows x 9 columns]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_csv('training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
